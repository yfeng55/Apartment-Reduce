2016-02-16 15:07:50,193 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 15:07:50,861 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 15:07:50,864 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 15:07:51,484 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 15:07:51,486 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 15:07:51,498 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 15:07:51,549 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 15:07:51,844 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local2112480691_0001
2016-02-16 15:07:52,467 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 15:07:52,468 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local2112480691_0001
2016-02-16 15:07:52,473 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 15:07:52,495 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:07:52,504 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 15:07:52,689 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 15:07:52,690 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2112480691_0001_m_000000_0
2016-02-16 15:07:52,770 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:07:52,806 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:07:52,810 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-16 15:07:52,950 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 15:07:52,951 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 15:07:52,951 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 15:07:52,951 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 15:07:52,952 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 15:07:52,961 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 15:07:52,977 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 15:07:52,979 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 15:07:52,982 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 15:07:52,982 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 135; bufvoid = 104857600
2016-02-16 15:07:52,982 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
2016-02-16 15:07:53,008 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 15:07:53,013 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2112480691_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 15:07:53,036 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 15:07:53,037 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2112480691_0001_m_000000_0' done.
2016-02-16 15:07:53,037 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2112480691_0001_m_000000_0
2016-02-16 15:07:53,037 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 15:07:53,046 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 15:07:53,046 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2112480691_0001_r_000000_0
2016-02-16 15:07:53,072 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:07:53,073 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:07:53,080 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@43aa56b7
2016-02-16 15:07:53,129 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 15:07:53,143 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2112480691_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 15:07:53,247 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2112480691_0001_m_000000_0 decomp: 161 len: 165 to MEMORY
2016-02-16 15:07:53,260 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 161 bytes from map-output for attempt_local2112480691_0001_m_000000_0
2016-02-16 15:07:53,262 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 161, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->161
2016-02-16 15:07:53,268 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 15:07:53,269 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:07:53,270 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 15:07:53,277 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:07:53,280 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-16 15:07:53,285 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 161 bytes to disk to satisfy reduce memory limit
2016-02-16 15:07:53,286 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2016-02-16 15:07:53,287 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 15:07:53,287 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:07:53,287 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-16 15:07:53,288 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:07:53,301 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 15:07:53,316 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2112480691_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 15:07:53,322 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:07:53,322 INFO org.apache.hadoop.mapred.Task: Task attempt_local2112480691_0001_r_000000_0 is allowed to commit now
2016-02-16 15:07:53,324 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2112480691_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local2112480691_0001_r_000000
2016-02-16 15:07:53,333 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 15:07:53,336 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2112480691_0001_r_000000_0' done.
2016-02-16 15:07:53,337 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2112480691_0001_r_000000_0
2016-02-16 15:07:53,339 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 15:07:53,477 INFO org.apache.hadoop.mapreduce.Job: Job job_local2112480691_0001 running in uber mode : false
2016-02-16 15:07:53,479 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 15:07:53,480 INFO org.apache.hadoop.mapreduce.Job: Job job_local2112480691_0001 completed successfully
2016-02-16 15:07:53,504 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1288
		FILE: Number of bytes written=527670
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=12
		Map output bytes=135
		Map output materialized bytes=165
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=165
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=46
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=47
2016-02-16 15:09:02,200 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 15:09:02,950 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 15:09:02,955 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 15:09:03,663 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 15:09:03,666 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 15:09:03,679 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 15:09:03,730 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 15:09:04,105 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1562527084_0001
2016-02-16 15:09:04,730 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 15:09:04,731 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1562527084_0001
2016-02-16 15:09:04,740 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 15:09:04,761 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:09:04,767 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 15:09:04,955 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 15:09:04,957 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1562527084_0001_m_000000_0
2016-02-16 15:09:05,035 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:09:05,075 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:09:05,082 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-16 15:09:05,260 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 15:09:05,260 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 15:09:05,260 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 15:09:05,260 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 15:09:05,260 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 15:09:05,272 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 15:09:05,288 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 15:09:05,288 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 15:09:05,288 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 15:09:05,288 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 135; bufvoid = 104857600
2016-02-16 15:09:05,288 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
2016-02-16 15:09:05,308 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 15:09:05,316 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1562527084_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 15:09:05,336 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 15:09:05,337 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1562527084_0001_m_000000_0' done.
2016-02-16 15:09:05,338 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1562527084_0001_m_000000_0
2016-02-16 15:09:05,339 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 15:09:05,346 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 15:09:05,347 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1562527084_0001_r_000000_0
2016-02-16 15:09:05,372 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:09:05,373 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:09:05,379 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@31593221
2016-02-16 15:09:05,426 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 15:09:05,441 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1562527084_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 15:09:05,539 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1562527084_0001_m_000000_0 decomp: 161 len: 165 to MEMORY
2016-02-16 15:09:05,553 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 161 bytes from map-output for attempt_local1562527084_0001_m_000000_0
2016-02-16 15:09:05,556 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 161, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->161
2016-02-16 15:09:05,560 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 15:09:05,561 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:09:05,562 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 15:09:05,572 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:09:05,577 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-16 15:09:05,578 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 161 bytes to disk to satisfy reduce memory limit
2016-02-16 15:09:05,580 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2016-02-16 15:09:05,583 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 15:09:05,583 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:09:05,584 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-16 15:09:05,584 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:09:05,599 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 15:09:05,609 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1562527084_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 15:09:05,617 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:09:05,617 INFO org.apache.hadoop.mapred.Task: Task attempt_local1562527084_0001_r_000000_0 is allowed to commit now
2016-02-16 15:09:05,618 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1562527084_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local1562527084_0001_r_000000
2016-02-16 15:09:05,623 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 15:09:05,625 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1562527084_0001_r_000000_0' done.
2016-02-16 15:09:05,627 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1562527084_0001_r_000000_0
2016-02-16 15:09:05,627 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 15:09:05,733 INFO org.apache.hadoop.mapreduce.Job: Job job_local1562527084_0001 running in uber mode : false
2016-02-16 15:09:05,734 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 15:09:05,735 INFO org.apache.hadoop.mapreduce.Job: Job job_local1562527084_0001 completed successfully
2016-02-16 15:09:05,755 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1288
		FILE: Number of bytes written=527670
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=12
		Map output bytes=135
		Map output materialized bytes=165
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=165
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=68
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=47
2016-02-16 15:09:28,918 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 15:09:29,620 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 15:09:29,624 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 15:09:30,579 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 15:09:30,591 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 15:09:30,627 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 15:09:30,691 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 15:09:31,022 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local531652280_0001
2016-02-16 15:09:31,629 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 15:09:31,630 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local531652280_0001
2016-02-16 15:09:31,637 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 15:09:31,657 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:09:31,660 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 15:09:31,851 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 15:09:31,854 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local531652280_0001_m_000000_0
2016-02-16 15:09:31,924 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:09:31,945 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:09:31,950 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-16 15:09:32,050 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 15:09:32,051 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 15:09:32,051 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 15:09:32,051 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 15:09:32,051 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 15:09:32,057 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 15:09:32,067 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 15:09:32,067 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 15:09:32,067 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 15:09:32,068 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 135; bufvoid = 104857600
2016-02-16 15:09:32,068 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
2016-02-16 15:09:32,077 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 15:09:32,081 INFO org.apache.hadoop.mapred.Task: Task:attempt_local531652280_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 15:09:32,090 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 15:09:32,090 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local531652280_0001_m_000000_0' done.
2016-02-16 15:09:32,090 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local531652280_0001_m_000000_0
2016-02-16 15:09:32,091 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 15:09:32,094 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 15:09:32,094 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local531652280_0001_r_000000_0
2016-02-16 15:09:32,104 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:09:32,105 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:09:32,111 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@9240189
2016-02-16 15:09:32,124 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 15:09:32,132 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local531652280_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 15:09:32,180 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local531652280_0001_m_000000_0 decomp: 161 len: 165 to MEMORY
2016-02-16 15:09:32,185 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 161 bytes from map-output for attempt_local531652280_0001_m_000000_0
2016-02-16 15:09:32,187 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 161, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->161
2016-02-16 15:09:32,188 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 15:09:32,189 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:09:32,189 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 15:09:32,197 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:09:32,197 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-16 15:09:32,198 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 161 bytes to disk to satisfy reduce memory limit
2016-02-16 15:09:32,199 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2016-02-16 15:09:32,199 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 15:09:32,200 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:09:32,201 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-16 15:09:32,201 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:09:32,215 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 15:09:32,222 INFO org.apache.hadoop.mapred.Task: Task:attempt_local531652280_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 15:09:32,224 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:09:32,224 INFO org.apache.hadoop.mapred.Task: Task attempt_local531652280_0001_r_000000_0 is allowed to commit now
2016-02-16 15:09:32,225 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local531652280_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local531652280_0001_r_000000
2016-02-16 15:09:32,230 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 15:09:32,230 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local531652280_0001_r_000000_0' done.
2016-02-16 15:09:32,230 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local531652280_0001_r_000000_0
2016-02-16 15:09:32,231 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 15:09:32,633 INFO org.apache.hadoop.mapreduce.Job: Job job_local531652280_0001 running in uber mode : false
2016-02-16 15:09:32,634 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 15:09:32,636 INFO org.apache.hadoop.mapreduce.Job: Job job_local531652280_0001 completed successfully
2016-02-16 15:09:32,649 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1288
		FILE: Number of bytes written=524882
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=12
		Map output bytes=135
		Map output materialized bytes=165
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=165
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=47
